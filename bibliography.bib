@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	urldate = {2016-02-15},
	journal = {PLoS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	pages = {e1003285}
}

@article{taschuk_ten_2017,
	title = {Ten simple rules for making research software more robust},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005412},
	doi = {10.1371/journal.pcbi.1005412},
	abstract = {Author summary Many researchers have found out the hard way that there‚Äôs a world of difference between ‚Äúworks for me on my machine‚Äù and ‚Äúworks for other people on theirs.‚Äù Many common challenges can be avoided by following a few simple rules; doing so not only improves reproducibility but can accelerate research.},
	number = {4},
	urldate = {2017-04-18},
	journal = {PLOS Computational Biology},
	author = {Taschuk, Morgan and Wilson, Greg},
	month = apr,
	year = {2017},
	keywords = {Computer software, bioinformatics, Operating Systems, Reproducibility, software development, Software tools, Software Engineering, Sequence alignment},
	pages = {e1005412}
}

@article{rule_ten_2019,
	title = {Ten simple rules for writing and sharing computational analyses in {Jupyter} {Notebooks}},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007007},
	doi = {10.1371/journal.pcbi.1007007},
	language = {en},
	number = {7},
	urldate = {2019-08-01},
	journal = {PLOS Computational Biology},
	author = {Rule, Adam and Birmingham, Amanda and Zuniga, Cristal and Altintas, Ilkay and Huang, Shih-Cheng and Knight, Rob and Moshiri, Niema and Nguyen, Mai H. and Rosenthal, Sara Brin and P√©rez, Fernando and Rose, Peter W.},
	month = jul,
	year = {2019},
	keywords = {Analysts, Computer and information sciences, Computer hardware, Data processing, Ecosystems, Graphical user interfaces, Metadata, Reproducibility},
	pages = {e1007007}
}

@article{perez-riverol_ten_2016,
	title = {Ten {Simple} {Rules} for {Taking} {Advantage} of {Git} and {GitHub}},
	volume = {12},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004947},
	doi = {10.1371/journal.pcbi.1004947},
	language = {en},
	number = {7},
	urldate = {2019-08-01},
	journal = {PLOS Computational Biology},
	author = {Perez-Riverol, Yasset and Gatto, Laurent and Wang, Rui and Sachsenberg, Timo and Uszkoreit, Julian and Leprevost, Felipe da Veiga and Fufezan, Christian and Ternent, Tobias and Eglen, Stephen J. and Katz, Daniel S. and Pollard, Tom J. and Konovalov, Alexander and Flight, Robert M. and Blin, Kai and Vizca√≠no, Juan Antonio},
	month = jul,
	year = {2016},
	keywords = {Bioinformatics, Control systems, Health services research, Open source software, Scientific publishing, Software development, Source code, Web-based applications},
	pages = {e1004947}
}

@article{boettiger_introduction_2017,
	title = {An {Introduction} to {Rocker}: {Docker} {Containers} for {R}},
	volume = {9},
	issn = {2073-4859},
	shorttitle = {An {Introduction} to {Rocker}},
	url = {https://journal.r-project.org/archive/2017/RJ-2017-065/index.html},
	doi = {10.32614/RJ-2017-065},
	language = {en},
	number = {2},
	urldate = {2019-02-05},
	journal = {The R Journal},
	author = {Boettiger, Carl and Eddelbuettel, Dirk},
	year = {2017},
	pages = {527--536}
}

@article{molenaar_klikoscientific_2018,
	title = {Kliko‚Äî{The} scientific compute container format},
	volume = {25},
	issn = {2213-1337},
	url = {http://www.sciencedirect.com/science/article/pii/S2213133717300793},
	doi = {10.1016/j.ascom.2018.08.003},
	abstract = {Kliko is a Docker-based container specification for running one or multiple related compute jobs. The key concepts of Kliko are the encapsulation of data processing software into a container and the formalization of the input, output and task parameters. By formalizing the parameters, the software is represented as abstract building blocks with an uniform and consistent interface. The main advantage is enhanced scriptability and empowering pipeline composition. Formalization is realized by bundling a container with a Kliko file, which describes the IO and task parameters. This Kliko container can then be opened and run by a Kliko runner. The Kliko runner will parse the Kliko definition and gather the values for these parameters, for example by requesting user input or retrieving pre-defined values from disk. Parameters can be various primitive types, for example: float, int or the path to a file. This paper will also discuss the implementation of a support library named Kliko which can be used to create Kliko containers, parse Kliko definitions, andchain Kliko containers in workflows using a workflow manager library such as Luigi. The Kliko library can be used inside the container to interact with the Kliko runner. Finally to illustrate the applicability of the Kliko definition, this paper will discuss two reference implementations based on the Kliko library: RODRIGUES, a web-based Kliko container scheduler and output visualizer specifically for astronomical data, and VerMeerKAT, a multi-container workflow data reduction pipeline which is being used as a prototype pipeline for the commissioning of the MeerKAT radio telescope. The Kliko library is open source. The documentation and source code can be found on the main website.11https://github.com/gijzelaerr/kliko..},
	urldate = {2019-02-05},
	journal = {Astronomy and Computing},
	author = {Molenaar, G. and Makhathini, S. and Girard, J. N. and Smirnov, O.},
	month = oct,
	year = {2018},
	keywords = {Docker, Scientific computing, Pipelines, Astronomy, Containerization, Data reduction},
	pages = {1--9},
	annote = {Comment: 10 pages, 4 figues}
}

@article{kurtzer_singularity_2017,
	title = {Singularity: {Scientific} containers for mobility of compute},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Singularity},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0177459},
	doi = {10.1371/journal.pone.0177459},
	abstract = {Here we present Singularity, software developed to bring containers and reproducibility to scientific computing. Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms. Singularity is an open source initiative that harnesses the expertise of system and software engineers and researchers alike, and integrates seamlessly into common workflows for both of these groups. As its primary use case, Singularity brings mobility of computing to both users and HPC centers, providing a secure means to capture and distribute software and compute environments. This ability to create and deploy reproducible environments across these centers, a previously unmet need, makes Singularity a game changing development for computational science.},
	number = {5},
	urldate = {2017-06-28},
	journal = {PLOS ONE},
	author = {Kurtzer, Gregory M. and Sochat, Vanessa and Bauer, Michael W.},
	month = may,
	year = {2017},
	keywords = {Computer software, Operating Systems, software development, Open source software, Software tools, Research validity, Tar, Software design},
	pages = {e0177459}
}

@article{kim_bio-docklets_2017,
	title = {Bio-{Docklets}: {Virtualization} {Containers} for {Single}-{Step} {Execution} of {NGS} {Pipelines}.},
	copyright = {¬© 2017, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	shorttitle = {Bio-{Docklets}},
	url = {http://www.biorxiv.org/content/early/2017/03/15/116962},
	doi = {10.1101/116962},
	abstract = {Background: Processing of Next-Generation Sequencing (NGS) data requires significant technical skills, involving installation, configuration, and execution of bioinformatics data pipelines, in addition to specialized post-analysis visualization and data mining software. In order to address some of these challenges, developers have leveraged virtualization containers, towards seamless deployment of preconfigured bioinformatics software and pipelines on any computational platform. Findings: We present an approach for abstracting the complex data operations of multi-step, bioinformatics pipelines for NGS data analysis. As examples, we have deployed two pipelines for RNAseq and CHIPseq, pre-configured within Docker virtualization containers we call Bio-Docklets. Each Bio-Docklet exposes a single data input and output endpoint and from a user perspective, running the pipelines is as simple as running a single bioinformatics tool. This is achieved through a ‚Äòmeta-script‚Äô that automatically starts the Bio-Docklets, and controls the pipeline execution through the BioBlend software library and the Galaxy Application Programming Interface (API). The pipelne output is postprocessed using the Visual Omics Explorer (VOE) framework, providing interactive data visualizations that users can access through a web browser. Conclusions: The goal of our approach is to enable easy access to NGS data analysis pipelines for nonbioinformatics experts, on any computing environment whether a laboratory workstation, university computer cluster, or a cloud service provider. Besides end-users, the Bio-Docklets also enables developers to programmatically deploy and run a large number of pipeline instances for concurrent analysis of multiple datasets.},
	language = {en},
	urldate = {2017-07-25},
	journal = {bioRxiv},
	author = {Kim, Baekdoo and Ali, Thahmina A. and Lijeron, Carlos and Afgan, Enis and Krampis, Konstantinos},
	month = mar,
	year = {2017},
	pages = {116962}
}

@article{emsley_framework_2018,
	title = {A {Framework} for the {Preservation} of a {Docker} {Container} {\textbar} {International} {Journal} of {Digital} {Curation}},
	volume = {12},
	url = {http://www.ijdc.net/article/view/509},
	doi = {10.2218/ijdc.v12i2.509},
	abstract = {Reliably building and maintaining systems across environments is a continuing 
problem. A project or experiment may run for years. Software and hardware may 
change as can the operating system. Containerisation is a technology that is used in a variety of companies, such as Google, Amazon and IBM, in addition to scientific projects to rapidly deploy a set of services repeatably. Using Dockerfiles to ensure that a container is built repeatably, to allow conformance and easy updating when changes take place, are becoming common within projects. It's seen as part of sustainable software development. Containerisation technology occupies a dual space: it is both a repository of software and software itself. In considering Docker in this fashion, we 
should verify that the Dockerfile can be reproduced. Using a subset of the Dockerfile specification, a domain specific language is created to ensure that Docker files can be reused at a later stage to recreate the original environment. We provide a simple framework to address the question of the preservation of containers and its environment. We present experiments on an existing Dockerfile and conclude with a discussion of future work. Taking our work, a pipeline was implemented to check that a defined Dockerfile conforms to our desired model, extracts the Docker and operating 
system details. This will help the reproducibility of results, by creating the machine  environment and package versions. It also helps development and testing by ensuring that the system is repeatably built and that any changes in the software environment can be equally shared in the Dockerfile. This work supports not only the citation process, but also the open scientific one by providing environmental details of the work. As a 
part of the pipeline to create the container, we capture the processes used and put them into the W3C PROV ontology. This provides the potential for providing it with a persistent identifier and traceability of the processes used to preserve the metadata. Our future work will look at the question of linking this output to a workflow ontology, to preserve the complete workflow with the commands and parameters to be given to the containers. We see this provenance as useful within the build process to provide a complete overview of the workflow.},
	language = {en-US},
	number = {2},
	urldate = {2019-01-07},
	journal = {International Journal of Digital Curation},
	author = {Emsley, Iain and De Roure, David},
	month = apr,
	year = {2018},
	keywords = {preservation, digital preservation, curation, DCC, digital curation, IJDC, International Journal of Digital Curation, UKOLN}
}


@article{boettiger_introduction_2015,
	title = {An {Introduction} to {Docker} for {Reproducible} {Research}},
	volume = {49},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/2723872.2723882},
	doi = {10.1145/2723872.2723882},
	abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
	number = {1},
	urldate = {2016-06-24},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Boettiger, Carl},
	month = jan,
	year = {2015},
	keywords = {Computer Science - Software Engineering},
	pages = {71--79},
	annote = {Reasons for not publishing reproducibly:
- lack of time
- lack of incenitves
- lack of familiar, intuitive tools
- think that summaries are enough
- does not fit into a researcher's workflow
¬†
Technical challenges:
- dependency hell
- imprecise documentation
- Code rot
- handling and learning multiple tools
¬†
Problem VM: Too much of a black box}
}

@article{marwick_madjebebe_2015,
	title = {1989-excavation-report-{Madjebebe}},
	doi = {10.6084/m9.figshare.1297059},
	urldate = {2016-06-24},
	author = {{Ben Marwick}},
	year = {2015}
}

@misc{marwick_how_2015,
	title = {How computers broke science ‚Äì and what we can do to fix it},
	copyright = {Copyright ¬© 2010‚Äì2019, The Conversation Trust (UK) Limited},
	url = {https://theconversation.com/how-computers-broke-science-and-what-we-can-do-to-fix-it-49938},
	abstract = {Virtually every researcher relies on computers to collect or analyze data. But when computers are opaque black boxes that manipulate data, it's impossible to replicate studies ‚Äì a core value for science.},
	language = {en},
	urldate = {2017-07-05},
	journal = {The Conversation},
	author = {Marwick, Ben},
	year = {2015}
}

@article{knoth_reproducibility_2017,
	title = {Reproducibility and {Practical} {Adoption} of {GEOBIA} with {Open}-{Source} {Software} in {Docker} {Containers}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://www.mdpi.com/2072-4292/9/3/290},
	doi = {10.3390/rs9030290},
	abstract = {Geographic Object-Based Image Analysis (GEOBIA) mostly uses proprietary software,but the interest in Free and Open-Source Software (FOSS) for GEOBIA is growing. This interest stems not only from cost savings, but also from benefits concerning reproducibility and collaboration. Technical challenges hamper practical reproducibility, especially when multiple software packages are required to conduct an analysis. In this study, we use containerization to package a GEOBIA workflow in a well-defined FOSS environment. We explore the approach using two software stacks to perform an exemplary analysis detecting destruction of buildings in bi-temporal images of a conflict area. The analysis combines feature extraction techniques with segmentation and object-based analysis to detect changes using automatically-defined local reference values and to distinguish disappeared buildings from non-target structures. The resulting workflow is published as FOSS comprising both the model and data in a ready to use Docker image and a user interface for interaction with the containerized workflow. The presented solution advances GEOBIA in the following aspects: higher transparency of methodology; easier reuse and adaption of workflows; better transferability between operating systems; complete description of the software environment; and easy application of workflows by image analysis experts and non-experts. As a result, it promotes not only the reproducibility of GEOBIA, but also its practical adoption.},
	language = {en},
	number = {3},
	urldate = {2017-03-23},
	journal = {Remote Sensing},
	author = {Knoth, Christian and N√ºst, Daniel},
	month = mar,
	year = {2017},
	keywords = {reproducible research, Docker, Reproducibility, containerization, GEOBIA, conflict monitoring, object-based image analysis, QGIS},
	pages = {290}
}

@article{chen_open_2019,
	title = {Open is not enough},
	volume = {15},
	copyright = {2018 Springer Nature Limited},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/s41567-018-0342-2},
	doi = {10.1038/s41567-018-0342-2},
	abstract = {The solutions adopted by the high-energy physics community to foster reproducible research are examples of best practices that could be embraced more widely. This first experience suggests that reproducibility requires going beyond openness.},
	language = {En},
	number = {2},
	urldate = {2019-02-10},
	journal = {Nature Physics},
	author = {Chen, Xiaoli and Dallmeier-Tiessen, S√ºnje and Dasler, Robin and Feger, Sebastian and Fokianos, Pamfilos and Gonzalez, Jose Benito and Hirvonsalo, Harri and Kousidis, Dinos and Lavasa, Artemis and Mele, Salvatore and Rodriguez, Diego Rodriguez and ≈†imko, Tibor and Smith, Tim and Trisovic, Ana and Trzcinska, Anna and Tsanaktsidis, Ioannis and Zimmermann, Markus and Cranmer, Kyle and Heinrich, Lukas and Watts, Gordon and Hildreth, Michael and Iglesias, Lara Lloret and Lassila-Perini, Kati and Neubert, Sebastian},
	month = feb,
	year = {2019},
	pages = {113},
	annote = {"Our own experience from opening up vast volumes of data is that openness cannot simply be tacked on as an afterthought at the end of the scientific endeavour. In addition, openness alone does not guarantee reproducibility or reusability, so it should not be pursued as a goal in itself. Focusing on data is also not enough: it needs to be accompanied by software, workflows and explanations, all of which need to be captured throughout the usual iterative and closed research lifecycle, ready for a timely open release with the results."}
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	issn = {1465-4644},
	url = {https://academic.oup.com/biostatistics/article/11/3/385/257703},
	doi = {10.1093/biostatistics/kxq028},
	abstract = {I am genuinely thrilled to see Biostatistics make a formal venture into computational reproducibility, and I congratulate the editors of Biostatistics on taking},
	language = {en},
	number = {3},
	urldate = {2019-08-01},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	month = jul,
	year = {2010},
	pages = {385--388}
}

@misc{stark_before_2018,
	type = {News},
	title = {Before reproducibility must come preproducibility},
	copyright = {2018 Nature},
	url = {http://www.nature.com/articles/d41586-018-05256-0},
	abstract = {Instead of arguing about whether results hold up, let‚Äôs push to provide enough information for others to repeat the experiments, says Philip Stark.},
	language = {EN},
	urldate = {2018-05-25},
	journal = {Nature},
	author = {Stark, Philip B.},
	month = may,
	year = {2018},
	doi = {10.1038/d41586-018-05256-0}
}

@article{halchenko_open_2012,
	title = {Open is {Not} {Enough}. {Let}'s {Take} the {Next} {Step}: {An} {Integrated}, {Community}-{Driven} {Computing} {Platform} for {Neuroscience}},
	volume = {6},
	issn = {1662-5196},
	shorttitle = {Open is {Not} {Enough}. {Let}'s {Take} the {Next} {Step}},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2012.00022/full},
	doi = {10.3389/fninf.2012.00022},
	abstract = {Open is Not Enough. Let's Take the Next Step: An Integrated, Community-Driven Computing Platform for Neuroscience},
	language = {English},
	urldate = {2019-08-01},
	journal = {Frontiers in Neuroinformatics},
	author = {Halchenko, Yaroslav O. and Hanke, Michael},
	year = {2012},
	keywords = {Debian, intergrated research software environment, NeuroDebian, Reproducible Research, research software maintenance}
}

@article{nust_opening_2017,
	title = {Opening the {Publication} {Process} with {Executable} {Research} {Compendia}},
	volume = {23},
	issn = {1082-9873},
	url = {http://www.dlib.org/dlib/january17/nuest/01nuest.html},
	doi = {10.1045/january2017-nuest},
	language = {en},
	number = {1/2},
	urldate = {2017-01-16},
	journal = {D-Lib Magazine},
	author = {N√ºst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, J√∂rg},
	month = jan,
	year = {2017}
}

@article{jupyter_binder_2018,
	title = {Binder 2.0 - {Reproducible}, interactive, sharable environments for science at scale},
	url = {https://conference.scipy.org/proceedings/scipy2018/project_jupyter.html},
	doi = {10.25080/Majora-4af1f417-011},
	urldate = {2018-08-21},
	journal = {Proceedings of the 17th Python in Science Conference},
	author = {Jupyter, Project and Bussonnier, Matthias and Forde, Jessica and Freeman, Jeremy and Granger, Brian and Head, Tim and Holdgraf, Chris and Kelley, Kyle and Nalvarte, Gladys and Osheroff, Andrew and Pacer, M. and Panda, Yuvi and Perez, Fernando and Ragan-Kelley, Benjamin and Willing, Carol},
	year = {2018},
	pages = {113--120}
}

@article{brinckman_computing_2018,
	title = {Computing environments for reproducibility: {Capturing} the ‚Äú{Whole} {Tale}‚Äù},
	issn = {0167-739X},
	shorttitle = {Computing environments for reproducibility},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X17310695},
	doi = {10.1016/j.future.2017.12.029},
	abstract = {The act of sharing scientific knowledge is rapidly evolving away from traditional articles and presentations to the delivery of executable objects that integrate the data and computational details (e.g., scripts and workflows) upon which the findings rely. This envisioned coupling of data and process is essential to advancing science but faces technical and institutional barriers. The Whole Tale¬†project aims to address these barriers by connecting computational, data-intensive research efforts with the larger research process‚Äîtransforming the knowledge discovery and dissemination process into one where data products are united with research articles to create ‚Äúliving publications‚Äù or tales. The Whole Tale¬†focuses on the full spectrum of science, empowering users in the long tail of science, and power users with demands for access to big data and compute resources. We report here on the design, architecture, and implementation of the Whole Tale¬†environment.},
	urldate = {2018-04-17},
	journal = {Future Generation Computer Systems},
	author = {Brinckman, Adam and Chard, Kyle and Gaffney, Niall and Hategan, Mihael and Jones, Matthew B. and Kowalik, Kacper and Kulasekaran, Sivakumar and Lud√§scher, Bertram and Mecum, Bryce D. and Nabrzyski, Jarek and Stodden, Victoria and Taylor, Ian J. and Turk, Matthew J. and Turner, Kandace},
	month = feb,
	year = {2018},
	keywords = {Reproducibility, Data sharing, Code sharing, Living publications, Provenance}
}

@misc{code_ocean_2019,
	title = {Code {Ocean}},
	url = {https://codeocean.com/},
	abstract = {Code Ocean is a research collaboration platform. Create, collaborate on, share, execute, and publish computational code and data from anywhere, with anyone.},
	language = {en},
	urldate = {2019-10-09},
	year = {2019}
}

@article{simko_reana_2019,
	title = {{REANA}: {A} {System} for {Reusable} {Research} {Data} {Analyses}},
	volume = {214},
	copyright = {¬© The Authors, published by EDP Sciences, 2019},
	issn = {2100-014X},
	shorttitle = {{REANA}},
	url = {https://www.epj-conferences.org/articles/epjconf/abs/2019/19/epjconf_chep2018_06034/epjconf_chep2018_06034.html},
	doi = {10.1051/epjconf/201921406034},
	abstract = {The revalidation, reinterpretation and reuse of research data analyses requires having access to the original computing environment, the experimental datasets, the analysis software, and the computational workflow steps which were used by researchers to produce the original scientific results in the first place.REANA (Reusable Analyses) is a nascent platform enabling researchers to structure their research data analyses in view of enabling future reuse. The analysis is described by means of a YAML file that captures sufficient information about the analysis assets, parameters and processes. The REANA platform consists of a set of micro-services allowing to launch and monitor container-based computational workflow jobs on the cloud. The REANA user interface and the command-line client enables researchers to easily rerun analysis workflows with new input parameters. The REANA platform aims at supporting several container technologies (Docker), workflow engines (CWL, Yadage), shared storage systems (Ceph, EOS) and compute cloud infrastructures (Ku-bernetes/OpenStack, HTCondor) used by the community.REANA was developed with the particle physics use case in mind and profits from synergies with general reusable research data analysis patterns in other scientific disciplines, such as bioinformatics and life sciences.},
	language = {en},
	urldate = {2019-10-09},
	journal = {EPJ Web of Conferences},
	author = {≈†imko, Tibor and Heinrich, Lukas and Hirvonsalo, Harri and Kousidis, Dinos and Rodr√≠guez, Diego},
	year = {2019},
	pages = {06034}
}

@misc{nust_author_2017,
	title = {Author {Carpentry} : {Docker} for reproducible research},
	url = {https://nuest.github.io/docker-reproducible-research/},
	urldate = {2019-12-05},
	journal = {Author Carpentry : Docker for reproducible research},
	author = {N√ºst, Daniel},
	year = {2017}
}

@misc{chapman_reproducible_2018,
	type = {Blog},
	title = {Reproducible data science environments with {Docker} {\textbar} {Phil} {Chapman}'s {Blog}},
	url = {https://chapmandu2.github.io/post/2018/05/26/reproducible-data-science-environments-with-docker/},
	urldate = {2019-12-05},
	author = {Chapman, Phil},
	month = may,
	year = {2018}
}

@misc{ropensci_labs_r_2015,
	title = {R {Docker} tutorial},
	url = {https://ropenscilabs.github.io/r-docker-tutorial/},
	urldate = {2019-12-05},
	author = {{rOpenSci Labs}},
	year = {2015},
	note = {https://github.com/ropenscilabs/r-docker-tutorial}
}

@misc{udemy_docker_2019,
	title = {Docker {Containers} for {Data} {Science} and {Reproducible} {Research}},
	url = {https://www.udemy.com/course/docker-containers-data-science-reproducible-research/},
	abstract = {Course Tutorial to make your work reproducible using Docker Containers},
	language = {en-us},
	urldate = {2019-12-05},
	journal = {Udemy},
	author = {{Udemy} and Zhbanko, Vladimir},
	month = jul,
	year = {2019}
}

@misc{psomopoulos_lesson_2017,
	title = {Lesson "{Docker} and {Reproducibility}" in {Workshop} "{Reproducible} analysis and {Research} {Transparency}"},
	url = {https://reproducible-analysis-workshop.readthedocs.io/en/latest/8.Intro-Docker.html},
	journal = {Reproducible analysis and Research Transparency},
	author = {Psomopoulos, Fotis E.},
	month = dec,
	year = {2017},
	note = {This workshop was part of the Open Science Tools, Data \& Technologies for Efficient Ecological \& Evolutionary Research Symposium, organized by NIOO-KNAW and DANS-KNAW on 7 \& 8 December 2017 at the Amsterdam Science Park.
https://nioo.knaw.nl/en/open-science-tools}
}

@article{wilson_best_2014,
	title = {Best {Practices} for {Scientific} {Computing}},
	volume = {12},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745},
	doi = {10.1371/journal.pbio.1001745},
	abstract = {We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.},
	language = {en},
	number = {1},
	urldate = {2019-12-05},
	journal = {PLOS Biology},
	author = {Wilson, Greg and Aruliah, D. A. and Brown, C. Titus and Hong, Neil P. Chue and Davis, Matt and Guy, Richard T. and Haddock, Steven H. D. and Huff, Kathryn D. and Mitchell, Ian M. and Plumbley, Mark D. and Waugh, Ben and White, Ethan P. and Wilson, Paul},
	month = jan,
	year = {2014},
	keywords = {Computer software, Computers, Open source software, Programming languages, Research validity, Scientists, Software development, Software tools},
	pages = {e1001745}
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	number = {6},
	urldate = {2017-07-20},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	keywords = {Computer software, Reproducibility, Source code, Software tools, data management, Data processing, Control systems, Programming languages},
	pages = {e1005510}
}

@misc{wikipedia_contributors_docker_2019,
	title = {Docker (software)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Docker_(software)&oldid=928441083},
	abstract = {Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers. Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels. All containers are run by a single operating-system kernel and are thus more lightweight than virtual machines.The service has both free and premium tiers. The software that hosts the containers is called Docker Engine. It was first started in 2013 and is developed by Docker, Inc.},
	language = {en},
	urldate = {2019-12-05},
	journal = {Wikipedia},
	author = {{Wikipedia contributors}},
	month = nov,
	year = {2019},
	note = {Page Version ID: 928441083},
	file = {Snapshot:/home/daniel/Zotero/storage/BWYNV5Z4/index.html:text/html}
}

@misc{docker_inc_dockerfile_2019,
	title = {Dockerfile reference},
	copyright = {Copyright ¬© 2019 Docker Inc. All rights reserved.},
	shorttitle = {https},
	url = {https://docs.docker.com/engine/reference/builder/},
	abstract = {Dockerfiles use a simple DSL which allows you to automate the steps you would normally manually take to create an image.},
	language = {en},
	urldate = {2019-12-05},
	journal = {Docker Documentation},
	author = {{Docker Inc.}},
	month = dec,
	year = {2019},
	file = {Snapshot:/home/daniel/Zotero/storage/NNGFKYPN/builder.html:text/html}
}

@misc{docker_inc_official_2019,
	title = {Official {Images} on {Docker} {Hub}},
	url = {https://docs.docker.com/docker-hub/official_images/},
	abstract = {Guidelines for Official Images on Docker Hub},
	language = {en},
	urldate = {2019-12-05},
	journal = {Docker Documentation},
	author = {{Docker Inc.}},
	month = dec,
	year = {2019},
	file = {Snapshot:/home/daniel/Zotero/storage/DLF4TJIQ/official_images.html:text/html}
}

@misc{preston-werner_semantic_2013,
	title = {Semantic {Versioning} 2.0.0},
	url = {https://semver.org/},
	abstract = {Semantic Versioning spec and website},
	language = {en},
	urldate = {2019-12-05},
	journal = {Semantic Versioning},
	author = {Preston-Werner, Tom},
	month = jun,
	year = {2013}
}

@misc{opencontainers_image-spec_2017,
	title = {opencontainers/image-spec v1.0.1 - {Annotations}},
	url = {https://github.com/opencontainers/image-spec/blob/v1.0.1/annotations.md},
	abstract = {OCI Image Format. Contribute to opencontainers/image-spec development by creating an account on GitHub.},
	language = {en},
	urldate = {2019-12-05},
	journal = {GitHub},
	author = {{Opencontainers}},
	month = nov,
	year = {2017}
}

@article{nust_containerit_2019,
	title = {containerit: {Generating} {Dockerfiles} for reproducible research with {R}},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {containerit},
	url = {https://joss.theoj.org/papers/10.21105/joss.01603},
	doi = {10.21105/joss.01603},
	number = {40},
	urldate = {2019-12-05},
	journal = {Journal of Open Source Software},
	author = {N√ºst, Daniel and Hinz, Matthias},
	month = aug,
	year = {2019},
	pages = {1603}
}

@misc{stencila_dockta_2019,
	title = {stencila/dockta},
	copyright = {Apache-2.0},
	url = {https://github.com/stencila/dockta},
	abstract = {üê≥ A Docker image builder for researchers. Contribute to stencila/dockta development by creating an account on GitHub.},
	urldate = {2019-12-05},
	publisher = {Stencila},
	author = {{Stencila}},
	month = nov,
	year = {2019},
	note = {original-date: 2018-10-04T05:00:17Z},
	keywords = {docker, dockerfile, nodejs, python, r, reproducibility}
}
